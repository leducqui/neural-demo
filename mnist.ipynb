{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images.reshape(-1, 28, 28, 1)\n",
    "Y_train = mnist.train.labels\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)\n",
    "X_test = mnist.test.images.reshape(-1, 28, 28, 1)\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Valid', \n",
    "                              activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Valid', \n",
    "                              activation ='relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size = (2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(120, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(84, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               61560     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 99,038\n",
      "Trainable params: 99,038\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 30s 551us/step - loss: 0.9078 - acc: 0.6829\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 31s 561us/step - loss: 0.2980 - acc: 0.9073\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 31s 567us/step - loss: 0.2202 - acc: 0.9305\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 32s 573us/step - loss: 0.1801 - acc: 0.9428\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 31s 565us/step - loss: 0.1543 - acc: 0.9515\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 32s 578us/step - loss: 0.1342 - acc: 0.9571\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 31s 571us/step - loss: 0.1193 - acc: 0.9622\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 32s 579us/step - loss: 0.1095 - acc: 0.9655\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 31s 566us/step - loss: 0.1019 - acc: 0.9671\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 31s 569us/step - loss: 0.0945 - acc: 0.9702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24b814e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 230us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09932954489355907, 0.9677]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Result: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_no = 50\n",
    "plt.imshow(X_test[test_no][:,:,0])\n",
    "print('Predicted Result: {}'.format(predict[test_no].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('MNIST_weight.h5')\n",
    "model.save('MNIST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
